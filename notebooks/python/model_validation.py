# %% [markdown]
# # ValidaÃ§Ã£o AvanÃ§ada de Modelo LSTM
# 
# Este notebook demonstra a implementaÃ§Ã£o completa da **validaÃ§Ã£o avanÃ§ada** do modelo LSTM para previsÃ£o meteorolÃ³gica.
# 
# ## Objetivos da ValidaÃ§Ã£o:
# 
# âœ… **Pipeline de treinamento completo**
# - PreparaÃ§Ã£o de sequÃªncias temporais
# - Batch processing para grandes volumes  
# - Validation split temporal (nÃ£o aleatÃ³rio)
# 
# âœ… **Cross-validation temporal para sÃ©ries temporais**
# - Walk-forward validation
# - PreservaÃ§Ã£o de ordem cronolÃ³gica
# - ValidaÃ§Ã£o temporal robusta
# 
# âœ… **OtimizaÃ§Ã£o de hiperparÃ¢metros com grid search**
# - Learning rate: 0.001, 0.0001, 0.00001
# - Batch size: 16, 32, 64, 128
# - Sequence length: 12, 24, 48, 72 horas
# 
# âœ… **ValidaÃ§Ã£o com mÃ©tricas especÃ­ficas para meteorologia**
# - MAE para precipitaÃ§Ã£o (mm/h)
# - RMSE para variÃ¡veis contÃ­nuas
# - Skill Score para eventos de chuva
# - **Target: Accuracy > 75% para classificaÃ§Ã£o de eventos**
# 
# ## CritÃ©rios de Sucesso:
# - ğŸ¯ **Accuracy > 75%** em previsÃ£o de chuva 24h
# - ğŸ¯ **MAE < 2.0 mm/h** para precipitaÃ§Ã£o
# - ğŸ¯ **RMSE < 3.0 mm/h** para precipitaÃ§Ã£o

# %%
# Imports necessÃ¡rios
import sys
import warnings
from pathlib import Path

# Adicionar path do projeto
sys.path.append(str(Path(__file__).parent.parent.parent))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import json

# Pipeline personalizado
from scripts.training_pipeline import (
    TrainingPipeline, 
    TemporalDataSplitter, 
    MeteorologicalMetrics,
    LSTMModelBuilder,
    TEMPORAL_VALIDATION_CONFIG,
    HYPERPARAMETER_GRID,
    RAIN_THRESHOLDS,
    METEOROLOGICAL_FEATURES
)

# ConfiguraÃ§Ãµes
warnings.filterwarnings('ignore')
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

print("ğŸš€ ValidaÃ§Ã£o AvanÃ§ada de Modelo LSTM")
print("=" * 50)
print(f"ğŸ“Š Features meteorolÃ³gicas: {len(METEOROLOGICAL_FEATURES)}")
print(f"ğŸ”„ ConfiguraÃ§Ã£o de validaÃ§Ã£o temporal: {TEMPORAL_VALIDATION_CONFIG}")
print(f"ğŸ¯ Thresholds de chuva: {RAIN_THRESHOLDS}")

# %% [markdown]
# ## 1. ConfiguraÃ§Ã£o e Carregamento de Dados

# %%
# Inicializar pipeline
pipeline = TrainingPipeline()

# Carregar dados
print("ğŸ“¥ Carregando dados processados...")
try:
    data = pipeline.load_data()
    print(f"âœ… Dados carregados com sucesso: {data.shape}")
    print(f"ğŸ“… PerÃ­odo: {data['timestamp'].min()} atÃ© {data['timestamp'].max()}")
    print(f"ğŸ”¢ Colunas disponÃ­veis: {len(data.columns)}")
    
    # Verificar features disponÃ­veis
    available_features = [col for col in METEOROLOGICAL_FEATURES if col in data.columns]
    print(f"ğŸŒ¦ï¸  Features meteorolÃ³gicas disponÃ­veis: {len(available_features)}/{len(METEOROLOGICAL_FEATURES)}")
    
    if len(available_features) < len(METEOROLOGICAL_FEATURES):
        missing_features = set(METEOROLOGICAL_FEATURES) - set(available_features)
        print(f"âš ï¸  Features faltando: {missing_features}")
    
except Exception as e:
    print(f"âŒ Erro ao carregar dados: {e}")
    print("ğŸ’¡ Execute primeiro o preprocessamento de dados")

# %%
# AnÃ¡lise rÃ¡pida dos dados
if 'data' in locals():
    print("ğŸ“Š EstatÃ­sticas dos dados:")
    
    # Verificar coluna de precipitaÃ§Ã£o
    precip_cols = [col for col in data.columns if 'precipitacao' in col.lower()]
    if precip_cols:
        precip_col = precip_cols[0]
        precip_data = data[precip_col]
        
        print(f"\nğŸŒ§ï¸  EstatÃ­sticas de precipitaÃ§Ã£o ({precip_col}):")
        print(f"   MÃ©dia: {precip_data.mean():.3f} mm/h")
        print(f"   Mediana: {precip_data.median():.3f} mm/h")
        print(f"   MÃ¡ximo: {precip_data.max():.3f} mm/h")
        print(f"   % sem chuva: {(precip_data == 0).sum() / len(precip_data) * 100:.1f}%")
        print(f"   % chuva leve (>0.1): {(precip_data >= 0.1).sum() / len(precip_data) * 100:.1f}%")
        print(f"   % chuva moderada (>2.5): {(precip_data >= 2.5).sum() / len(precip_data) * 100:.1f}%")
        print(f"   % chuva forte (>10): {(precip_data >= 10.0).sum() / len(precip_data) * 100:.1f}%")
        
        # Visualizar distribuiÃ§Ã£o
        fig, axes = plt.subplots(1, 2, figsize=(12, 4))
        
        # Histograma da precipitaÃ§Ã£o
        axes[0].hist(precip_data[precip_data > 0], bins=50, alpha=0.7, color='skyblue')
        axes[0].set_xlabel('PrecipitaÃ§Ã£o (mm/h)')
        axes[0].set_ylabel('FrequÃªncia')
        axes[0].set_title('DistribuiÃ§Ã£o da PrecipitaÃ§Ã£o (> 0)')
        axes[0].set_yscale('log')
        
        # SÃ©rie temporal (amostra)
        sample_data = data.sample(n=min(1000, len(data))).sort_values('timestamp')
        axes[1].plot(sample_data['timestamp'], sample_data[precip_col], alpha=0.7, color='blue')
        axes[1].set_xlabel('Tempo')
        axes[1].set_ylabel('PrecipitaÃ§Ã£o (mm/h)')
        axes[1].set_title('SÃ©rie Temporal da PrecipitaÃ§Ã£o (Amostra)')
        axes[1].tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        plt.show()

# %% [markdown]
# ## 2. ValidaÃ§Ã£o Cruzada Temporal

# %%
print("ğŸ”„ Executando ValidaÃ§Ã£o Cruzada Temporal")
print("=" * 40)

# Configurar validaÃ§Ã£o temporal
data_splitter = TemporalDataSplitter(TEMPORAL_VALIDATION_CONFIG)

# Demonstrar como funcionam os splits temporais
print("ğŸ“… DemonstraÃ§Ã£o dos splits temporais:")
splits_demo = list(data_splitter.create_temporal_splits(data))

print(f"âœ… Gerados {len(splits_demo)} folds temporais")
print("\nğŸ“Š Resumo dos folds:")

for i, (train_split, val_split) in enumerate(splits_demo[:3]):  # Mostrar apenas os 3 primeiros
    train_start = train_split['timestamp'].min()
    train_end = train_split['timestamp'].max()
    val_start = val_split['timestamp'].min()
    val_end = val_split['timestamp'].max()
    
    print(f"\n   Fold {i+1}:")
    print(f"   ğŸ“ˆ Treino: {train_start.strftime('%Y-%m-%d')} atÃ© {train_end.strftime('%Y-%m-%d')} ({len(train_split)} amostras)")
    print(f"   ğŸ“Š ValidaÃ§Ã£o: {val_start.strftime('%Y-%m-%d')} atÃ© {val_end.strftime('%Y-%m-%d')} ({len(val_split)} amostras)")

# %%
# Executar validaÃ§Ã£o cruzada temporal completa
print("\nğŸš€ Executando validaÃ§Ã£o cruzada temporal completa...")

try:
    cv_results = pipeline.run_temporal_cross_validation(max_folds=3)  # Reduzido para demonstraÃ§Ã£o
    
    if cv_results:
        print("\nğŸ“Š RESULTADOS DA VALIDAÃ‡ÃƒO CRUZADA TEMPORAL")
        print("=" * 50)
        
        # MÃ©tricas principais
        metrics_to_show = ['accuracy', 'mae', 'rmse', 'f1_score']
        
        for metric in metrics_to_show:
            mean_key = f'{metric}_mean'
            std_key = f'{metric}_std'
            
            if mean_key in cv_results:
                mean_val = cv_results[mean_key]
                std_val = cv_results.get(std_key, 0)
                print(f"   {metric.upper()}: {mean_val:.3f} Â± {std_val:.3f}")
        
        # Verificar critÃ©rios de sucesso
        print("\nğŸ¯ CRITÃ‰RIOS DE SUCESSO:")
        accuracy_target = cv_results.get('meets_accuracy_target', False)
        mae_target = cv_results.get('meets_mae_target', False)
        overall_success = cv_results.get('overall_success', False)
        
        print(f"   Accuracy >= 75%: {'âœ…' if accuracy_target else 'âŒ'}")
        print(f"   MAE <= 2.0 mm/h: {'âœ…' if mae_target else 'âŒ'}")
        print(f"   Sucesso geral: {'âœ…' if overall_success else 'âŒ'}")
        
        # Visualizar resultados por fold
        if 'fold_results' in cv_results:
            fold_results = cv_results['fold_results']
            
            fig, axes = plt.subplots(2, 2, figsize=(12, 8))
            
            # MAE por fold
            mae_values = [fold['mae'] for fold in fold_results]
            axes[0, 0].plot(range(1, len(mae_values) + 1), mae_values, 'o-', color='red')
            axes[0, 0].axhline(y=2.0, color='red', linestyle='--', alpha=0.7, label='Target: 2.0')
            axes[0, 0].set_xlabel('Fold')
            axes[0, 0].set_ylabel('MAE (mm/h)')
            axes[0, 0].set_title('MAE por Fold')
            axes[0, 0].legend()
            axes[0, 0].grid(True, alpha=0.3)
            
            # Accuracy por fold
            acc_values = [fold.get('accuracy', 0) for fold in fold_results]
            axes[0, 1].plot(range(1, len(acc_values) + 1), acc_values, 'o-', color='green')
            axes[0, 1].axhline(y=0.75, color='green', linestyle='--', alpha=0.7, label='Target: 75%')
            axes[0, 1].set_xlabel('Fold')
            axes[0, 1].set_ylabel('Accuracy')
            axes[0, 1].set_title('Accuracy por Fold')
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)
            
            # RMSE por fold
            rmse_values = [fold['rmse'] for fold in fold_results]
            axes[1, 0].plot(range(1, len(rmse_values) + 1), rmse_values, 'o-', color='blue')
            axes[1, 0].axhline(y=3.0, color='blue', linestyle='--', alpha=0.7, label='Target: 3.0')
            axes[1, 0].set_xlabel('Fold')
            axes[1, 0].set_ylabel('RMSE (mm/h)')
            axes[1, 0].set_title('RMSE por Fold')
            axes[1, 0].legend()
            axes[1, 0].grid(True, alpha=0.3)
            
            # F1-Score por fold
            f1_values = [fold.get('f1_score', 0) for fold in fold_results]
            axes[1, 1].plot(range(1, len(f1_values) + 1), f1_values, 'o-', color='purple')
            axes[1, 1].set_xlabel('Fold')
            axes[1, 1].set_ylabel('F1-Score')
            axes[1, 1].set_title('F1-Score por Fold')
            axes[1, 1].grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.show()
    
    else:
        print("âŒ Nenhum resultado da validaÃ§Ã£o cruzada temporal")
        
except Exception as e:
    print(f"âŒ Erro durante validaÃ§Ã£o cruzada temporal: {e}")

# %% [markdown]
# ## 3. MÃ©tricas MeteorolÃ³gicas EspecÃ­ficas

# %%
print("ğŸŒ¦ï¸  DemonstraÃ§Ã£o das MÃ©tricas MeteorolÃ³gicas")
print("=" * 45)

# Criar dados sintÃ©ticos para demonstraÃ§Ã£o
np.random.seed(42)
n_samples = 1000

# Simular dados de precipitaÃ§Ã£o realistas
y_true = np.random.exponential(scale=0.5, size=n_samples)  # DistribuiÃ§Ã£o exponencial (comum para chuva)
y_true[y_true > 20] = 20  # Limitar valores extremos

# Simular prediÃ§Ãµes com algum ruÃ­do
y_pred = y_true + np.random.normal(0, 0.2, size=n_samples)
y_pred[y_pred < 0] = 0  # PrecipitaÃ§Ã£o nÃ£o pode ser negativa

print(f"ğŸ“Š Dados sintÃ©ticos gerados: {n_samples} amostras")
print(f"   PrecipitaÃ§Ã£o real - MÃ©dia: {y_true.mean():.3f}, Max: {y_true.max():.3f}")
print(f"   PrecipitaÃ§Ã£o predita - MÃ©dia: {y_pred.mean():.3f}, Max: {y_pred.max():.3f}")

# Calcular mÃ©tricas meteorolÃ³gicas
metrics_calc = MeteorologicalMetrics()
detailed_metrics = metrics_calc.calculate_precipitation_metrics(y_true, y_pred)

print("\nğŸ“ˆ MÃ‰TRICAS METEOROLÃ“GICAS DETALHADAS:")
print("=" * 40)

# MÃ©tricas bÃ¡sicas
print("ğŸ”¢ MÃ©tricas BÃ¡sicas:")
print(f"   MAE: {detailed_metrics['mae']:.3f} mm/h")
print(f"   RMSE: {detailed_metrics['rmse']:.3f} mm/h")
print(f"   MSE: {detailed_metrics['mse']:.3f}")

# MÃ©tricas por intensidade de chuva
print("\nğŸŒ§ï¸  MÃ©tricas por Intensidade:")
for intensity in ['light', 'moderate', 'heavy']:
    mae_key = f'mae_{intensity}'
    count_key = f'count_{intensity}'
    
    if mae_key in detailed_metrics and count_key in detailed_metrics:
        mae_val = detailed_metrics[mae_key]
        count_val = detailed_metrics[count_key]
        print(f"   {intensity.capitalize()}: MAE = {mae_val:.3f} mm/h ({count_val} amostras)")

# Skill Scores
print("\nğŸ¯ Skill Scores:")
for intensity in ['light', 'moderate', 'heavy']:
    skill_key = f'skill_score_{intensity}'
    if skill_key in detailed_metrics:
        skill_val = detailed_metrics[skill_key]
        print(f"   {intensity.capitalize()}: {skill_val:.3f}")

# MÃ©tricas de classificaÃ§Ã£o
print("\nğŸ“Š MÃ©tricas de ClassificaÃ§Ã£o (eventos de chuva):")
if 'accuracy' in detailed_metrics:
    print(f"   Accuracy: {detailed_metrics['accuracy']:.3f}")
if 'f1_score' in detailed_metrics:
    print(f"   F1-Score: {detailed_metrics['f1_score']:.3f}")
if 'auc' in detailed_metrics:
    print(f"   AUC: {detailed_metrics['auc']:.3f}")

# %%
# Visualizar mÃ©tricas meteorolÃ³gicas
fig, axes = plt.subplots(2, 2, figsize=(12, 8))

# Scatter plot: Real vs Predito
axes[0, 0].scatter(y_true, y_pred, alpha=0.5, s=10)
axes[0, 0].plot([0, y_true.max()], [0, y_true.max()], 'r--', alpha=0.8)
axes[0, 0].set_xlabel('PrecipitaÃ§Ã£o Real (mm/h)')
axes[0, 0].set_ylabel('PrecipitaÃ§Ã£o Predita (mm/h)')
axes[0, 0].set_title('Real vs Predito')
axes[0, 0].grid(True, alpha=0.3)

# Histograma dos erros
errors = y_pred - y_true
axes[0, 1].hist(errors, bins=30, alpha=0.7, color='orange')
axes[0, 1].axvline(x=0, color='red', linestyle='--', alpha=0.8)
axes[0, 1].set_xlabel('Erro (Predito - Real)')
axes[0, 1].set_ylabel('FrequÃªncia')
axes[0, 1].set_title(f'DistribuiÃ§Ã£o dos Erros (MAE: {detailed_metrics["mae"]:.3f})')

# MÃ©tricas por threshold
thresholds = [0.1, 0.5, 1.0, 2.5, 5.0, 10.0]
skill_scores = []

for threshold in thresholds:
    skill = metrics_calc.calculate_skill_score(y_true, y_pred, threshold)
    skill_scores.append(skill)

axes[1, 0].plot(thresholds, skill_scores, 'o-', color='purple')
axes[1, 0].set_xlabel('Threshold (mm/h)')
axes[1, 0].set_ylabel('Skill Score')
axes[1, 0].set_title('Skill Score por Threshold')
axes[1, 0].grid(True, alpha=0.3)

# Box plot das mÃ©tricas por intensidade
intensities = []
mae_by_intensity = []

for intensity in ['light', 'moderate', 'heavy']:
    if intensity == 'light':
        mask = (y_true >= 0) & (y_true < 2.5)
    elif intensity == 'moderate':
        mask = (y_true >= 2.5) & (y_true < 10.0)
    elif intensity == 'heavy':
        mask = y_true >= 10.0
    
    if np.sum(mask) > 0:
        errors_intensity = np.abs(y_pred[mask] - y_true[mask])
        intensities.append(intensity.capitalize())
        mae_by_intensity.append(errors_intensity)

if mae_by_intensity:
    axes[1, 1].boxplot(mae_by_intensity, labels=intensities)
    axes[1, 1].set_ylabel('Erro Absoluto (mm/h)')
    axes[1, 1].set_title('DistribuiÃ§Ã£o dos Erros por Intensidade')
    axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# %% [markdown]
# ## 4. OtimizaÃ§Ã£o de HiperparÃ¢metros

# %%
print("âš™ï¸  DemonstraÃ§Ã£o da OtimizaÃ§Ã£o de HiperparÃ¢metros")
print("=" * 50)

# Mostrar grid de hiperparÃ¢metros
print("ğŸ”§ Grid de HiperparÃ¢metros:")
for param, values in HYPERPARAMETER_GRID.items():
    print(f"   {param}: {values}")

# Simular otimizaÃ§Ã£o rÃ¡pida com dados reduzidos
print("\nğŸš€ Executando otimizaÃ§Ã£o de hiperparÃ¢metros (versÃ£o reduzida)...")

try:
    # Usar amostra menor para demonstraÃ§Ã£o
    if 'data' in locals() and len(data) > 10000:
        data_sample = data.sample(n=10000, random_state=42).sort_values('timestamp')
        print(f"ğŸ“Š Usando amostra de {len(data_sample)} registros para demonstraÃ§Ã£o")
    else:
        data_sample = data
    
    # Executar otimizaÃ§Ã£o com poucos trials
    hyperopt_results = pipeline.run_hyperparameter_optimization(max_trials=5)
    
    if hyperopt_results:
        print("\nğŸ“Š RESULTADOS DA OTIMIZAÃ‡ÃƒO DE HIPERPARÃ‚METROS")
        print("=" * 50)
        
        print(f"ğŸ† Melhor MAE: {hyperopt_results.get('best_mae', 'N/A'):.3f}")
        print(f"ğŸ”§ Melhores parÃ¢metros: {hyperopt_results.get('best_params', {})}")
        print(f"ğŸ”¢ Total de trials: {hyperopt_results.get('total_trials', 0)}")
        
        # Visualizar resultados dos trials
        if 'trial_results' in hyperopt_results:
            trial_results = hyperopt_results['trial_results']
            
            if len(trial_results) > 1:
                fig, axes = plt.subplots(1, 2, figsize=(12, 4))
                
                # MAE por trial
                trial_numbers = [r['trial'] for r in trial_results]
                mae_values = [r['mae'] for r in trial_results]
                
                axes[0].plot(trial_numbers, mae_values, 'o-', color='red')
                axes[0].set_xlabel('Trial')
                axes[0].set_ylabel('MAE (mm/h)')
                axes[0].set_title('MAE por Trial')
                axes[0].grid(True, alpha=0.3)
                
                # Accuracy por trial
                acc_values = [r.get('accuracy', 0) for r in trial_results]
                axes[1].plot(trial_numbers, acc_values, 'o-', color='green')
                axes[1].set_xlabel('Trial')
                axes[1].set_ylabel('Accuracy')
                axes[1].set_title('Accuracy por Trial')
                axes[1].grid(True, alpha=0.3)
                
                plt.tight_layout()
                plt.show()
            
            # Mostrar top 3 configuraÃ§Ãµes
            sorted_results = sorted(trial_results, key=lambda x: x['mae'])
            print(f"\nğŸ… TOP 3 CONFIGURAÃ‡Ã•ES:")
            
            for i, result in enumerate(sorted_results[:3]):
                print(f"\n   #{i+1} - MAE: {result['mae']:.3f}")
                if 'params' in result:
                    for param, value in result['params'].items():
                        print(f"      {param}: {value}")
    
    else:
        print("âŒ Nenhum resultado da otimizaÃ§Ã£o de hiperparÃ¢metros")

except Exception as e:
    print(f"âŒ Erro durante otimizaÃ§Ã£o de hiperparÃ¢metros: {e}")

# %% [markdown]
# ## 5. AnÃ¡lise de Performance e ConclusÃµes

# %%
print("ğŸ“ˆ AnÃ¡lise de Performance - Fase 3.2")
print("=" * 40)

# Resumo dos resultados (se disponÃ­veis)
if 'cv_results' in locals() and cv_results:
    print("ğŸ“Š RESUMO DA VALIDAÃ‡ÃƒO CRUZADA TEMPORAL:")
    
    accuracy_mean = cv_results.get('accuracy_mean', 0)
    mae_mean = cv_results.get('mae_mean', 0)
    rmse_mean = cv_results.get('rmse_mean', 0)
    
    print(f"   ğŸ¯ Accuracy mÃ©dia: {accuracy_mean:.3f}")
    print(f"   ğŸ“‰ MAE mÃ©dio: {mae_mean:.3f} mm/h")
    print(f"   ğŸ“Š RMSE mÃ©dio: {rmse_mean:.3f} mm/h")
    
    # AvaliaÃ§Ã£o dos critÃ©rios
    print("\nğŸ¯ AVALIAÃ‡ÃƒO DOS CRITÃ‰RIOS DE SUCESSO:")
    
    accuracy_ok = accuracy_mean >= 0.75
    mae_ok = mae_mean <= 2.0
    rmse_ok = rmse_mean <= 3.0
    
    print(f"   Accuracy >= 75%: {'âœ… PASSOU' if accuracy_ok else 'âŒ FALHOU'} ({accuracy_mean:.1%})")
    print(f"   MAE <= 2.0 mm/h: {'âœ… PASSOU' if mae_ok else 'âŒ FALHOU'} ({mae_mean:.3f})")
    print(f"   RMSE <= 3.0 mm/h: {'âœ… PASSOU' if rmse_ok else 'âŒ FALHOU'} ({rmse_mean:.3f})")
    
    overall_success = accuracy_ok and mae_ok and rmse_ok
    print(f"\nğŸ† RESULTADO GERAL: {'âœ… SUCESSO' if overall_success else 'âŒ PRECISA MELHORIAS'}")

if 'hyperopt_results' in locals() and hyperopt_results:
    print(f"\nâš™ï¸  MELHOR CONFIGURAÃ‡ÃƒO ENCONTRADA:")
    best_params = hyperopt_results.get('best_params', {})
    for param, value in best_params.items():
        print(f"   {param}: {value}")

# %%
print("\nğŸ“‹ CHECKLIST DA FASE 3.2")
print("=" * 30)

checklist = [
    ("Pipeline de treinamento completo", "âœ…"),
    ("PreparaÃ§Ã£o de sequÃªncias temporais", "âœ…"),
    ("Validation split temporal (nÃ£o aleatÃ³rio)", "âœ…"),
    ("Cross-validation temporal", "âœ…"),
    ("Walk-forward validation", "âœ…"),
    ("PreservaÃ§Ã£o de ordem cronolÃ³gica", "âœ…"),
    ("OtimizaÃ§Ã£o de hiperparÃ¢metros", "âœ…"),
    ("Grid search automatizado", "âœ…"),
    ("MÃ©tricas meteorolÃ³gicas especÃ­ficas", "âœ…"),
    ("MAE para precipitaÃ§Ã£o", "âœ…"),
    ("RMSE para variÃ¡veis contÃ­nuas", "âœ…"),
    ("Skill Score para eventos de chuva", "âœ…"),
    ("Accuracy > 75% para classificaÃ§Ã£o", "ğŸ”„ Em validaÃ§Ã£o"),
]

for item, status in checklist:
    print(f"   {status} {item}")

print(f"\nğŸ’¡ PRÃ“XIMOS PASSOS:")
print("   1. ğŸ”§ Executar pipeline completo: `make training-pipeline`")
print("   2. ğŸ“Š Validar mÃ©tricas: `make validate-model-metrics`")
print("   3. ğŸš€ Se critÃ©rios atendidos, prosseguir para Fase 4")
print("   4. ğŸ”„ Se nÃ£o, ajustar hiperparÃ¢metros e re-treinar")

print(f"\nğŸ“ COMANDOS ÃšTEIS:")
print("   - `make temporal-cv`: ValidaÃ§Ã£o cruzada temporal")
print("   - `make hyperopt`: OtimizaÃ§Ã£o de hiperparÃ¢metros")
print("   - `make training-pipeline`: Pipeline completo")
print("   - `make view-training-results`: Ver resultados")

# %% [markdown]
# ## 6. ConclusÃ£o da Fase 3.2
# 
# âœ… **ImplementaÃ§Ã£o Completa da Fase 3.2**
# 
# Esta implementaÃ§Ã£o cobre todos os requisitos especificados na documentaÃ§Ã£o:
# 
# ### âœ… Pipeline de Treinamento Completo
# - PreparaÃ§Ã£o automÃ¡tica de sequÃªncias temporais
# - Batch processing otimizado para grandes volumes
# - Validation split temporal que preserva ordem cronolÃ³gica
# 
# ### âœ… Cross-validation Temporal 
# - Walk-forward validation implementado
# - PreservaÃ§Ã£o rigorosa da ordem cronolÃ³gica
# - MÃºltiplos folds temporais com configuraÃ§Ã£o flexÃ­vel
# 
# ### âœ… OtimizaÃ§Ã£o de HiperparÃ¢metros
# - Grid search sistemÃ¡tico com parÃ¢metros definidos na documentaÃ§Ã£o
# - Learning rates: 0.001, 0.0001, 0.00001
# - Batch sizes: 16, 32, 64, 128
# - Sequence lengths: 12, 24, 48, 72 horas
# 
# ### âœ… MÃ©tricas MeteorolÃ³gicas EspecÃ­ficas
# - MAE estratificado por intensidade de chuva
# - RMSE para variÃ¡veis contÃ­nuas
# - Skill Score (Equitable Threat Score) para eventos de chuva
# - MÃ©tricas de classificaÃ§Ã£o para eventos (Accuracy, F1-Score, AUC)
# 
# ### ğŸ¯ CritÃ©rios de Sucesso Implementados
# - **Target: Accuracy > 75%** em previsÃ£o de chuva 24h
# - **Target: MAE < 2.0 mm/h** para precipitaÃ§Ã£o  
# - **Target: RMSE < 3.0 mm/h** para precipitaÃ§Ã£o
# 
# ### ğŸš€ Pronto para PrÃ³xima Fase
# A Fase 3.2 estÃ¡ **completa e funcional**. O sistema pode agora:
# 
# 1. Treinar modelos com validaÃ§Ã£o temporal rigorosa
# 2. Otimizar hiperparÃ¢metros sistematicamente
# 3. Avaliar performance com mÃ©tricas meteorolÃ³gicas especÃ­ficas
# 4. Validar se os critÃ©rios de sucesso sÃ£o atendidos
# 
# **PrÃ³ximo passo:** Fase 4 - Feature Forecast (PrevisÃ£o) 